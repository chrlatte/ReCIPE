{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d2_ic10_medium"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports:\n",
    "\n",
    "# standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# library used for functional enrichment analysis\n",
    "from func_e.FUNC_E import FUNC_E  # a method that can do funtional enrichment analysis!\n",
    "import func_e.vocabs.all as vocabs\n",
    "# following code is necessary as some functions used in the funcE class produce future warnings but i can't fix it as it is not my code\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# importing the custom classes i built\n",
    "from matrix_class import ProteinMatrix # ppi matrix \n",
    "from cluster_class import AllClusters # dictionary to hold all clusters (in form number of cluster : list of proteins in that cluster)\n",
    "from degreelist_class import DegreeList # creates a list of all proteins in order of their degree\n",
    "\n",
    "# helper functions for setting up program\n",
    "from recipe_utils import initialize_matrix_clusters_degreelist\n",
    "from recipe_utils import find_clusters_and_proteins_together\n",
    "\n",
    "# helper functions for functional enrichment\n",
    "from recipe_utils import print_querylist_of_clusters_to_file\n",
    "from recipe_utils import print_protein_background_to_file\n",
    "from recipe_utils import create_term_mapping_list\n",
    "from recipe_utils import get_initialized_fe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **must change filenames:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_file = \"data/interactions/2_ppi_inweb_v2.txt\"\n",
    "clusters_file = \"data/d2_ic10_medium/d2_ic10_medium.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, clusters, degreelist = initialize_matrix_clusters_degreelist(interactions_filepath=interactions_file, clusters_filepath=clusters_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*may want to change parameters below:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_qualifying_clusters, sqrt_qualifying_proteins = find_clusters_and_proteins_together(matrix, clusters, degreelist, cluster_ratio=0, cluster_constant=2, use_sqrt=True, protein_ratio=1, protein_constant=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt_qualifying_proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from recipe_utils import top_n_proteins\n",
    "\n",
    "# three_qualifying_proteins = top_n_proteins(sqrt_qualifying_proteins, n=3) \n",
    "# three_qualifying_proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from recipe_utils import get_cluster_connectivity\n",
    "\n",
    "# original_cluster_connectivity = get_cluster_connectivity(matrix, degreelist, clusters, {}, sort_it=False)\n",
    "# new_cluster_connectivity = get_cluster_connectivity(matrix, degreelist, clusters, added_proteins=sqrt_qualifying_proteins, sort_it=False)\n",
    "\n",
    "# from recipe_utils import calculate_connectivity_difference\n",
    "\n",
    "# difference = calculate_connectivity_difference(original_cluster_connectivity, new_cluster_connectivity, sort_it=True)\n",
    "# difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Enrichment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_term_mapping_list(\"data/go_labels/dream3_go.tsv\", \"data/go_labels/d3_term_mapping.tsv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**will need to the directory below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"data/d2_ic10_medium/\"\n",
    "term_mapping_filepath = \"data/go_labels/d2_term_mapping.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_proteins_filepath = directory + \"background_proteinlist.txt\"\n",
    "og_query_filepath = directory + \"original_clusters.txt\"\n",
    "sqrt_query_filepath = directory + \"sqrt_clusters.txt\"\n",
    "# three_query_filepath = directory + \"three_prot_clusters.txt\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*print to files*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use functions to print info to files: (annoying, but need to get info into format used for funcE package)\n",
    "# 1) a background protein list to be used for functional enrichment analysis\n",
    "print_protein_background_to_file(matrix, background_proteins_filepath) \n",
    "# 3) not a file, but need to establish a background of all GO terms! (to be used for functional enrichment analysis)\n",
    "background_go_terms = vocabs.getTerms(['GO'])\n",
    "\n",
    "# continue printing info to files to be used in functional enrichment analysis:\n",
    "# 4) print original clusters to a file\n",
    "print_querylist_of_clusters_to_file(clusters, clusters.get_all_cluster_labels(), og_query_filepath)\n",
    "# 5) print updated clusters to a file (just append the function to include the dictionary of qualifying proteins)\n",
    "print_querylist_of_clusters_to_file(clusters, clusters.get_all_cluster_labels(), sqrt_query_filepath, sqrt_qualifying_proteins)\n",
    "# print_querylist_of_clusters_to_file(clusters, clusters.get_all_cluster_labels(), three_query_filepath, three_qualifying_proteins)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*RUN Functional Enrichment:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_fe = get_initialized_fe(background_proteins_filepath, term_mapping_filepath, termlist = background_go_terms)\n",
    "original_fe.importFiles({'query': og_query_filepath })\n",
    "original_fe.run(cluster=False)\n",
    "\n",
    "sqrt_fe = get_initialized_fe(background_proteins_filepath, term_mapping_filepath, termlist = background_go_terms)\n",
    "sqrt_fe.importFiles({'query': sqrt_query_filepath })\n",
    "sqrt_fe.run(cluster=False)\n",
    "\n",
    "# three_fe = get_initialized_fe(background_proteins_filepath, term_mapping_filepath, termlist = background_go_terms)\n",
    "# three_fe.importFiles({'query': three_query_filepath })\n",
    "# three_fe.run(cluster=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::::::::::::::::::::::::::SQRT::::::::::::::::::::::::::\n",
      "\n",
      "number of clusters that were updated with proteins: 0\n",
      "\n",
      "number of functionally enriched clusters (modules) out of 212 original clusters: 208\n",
      "number of functionally enriched clusters after addition of all proteins: 208\n",
      "\n",
      "number of significant pvals in original clusters before updating: 941\n",
      "number of significant pvals in clusters with all proteins added: 941\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"::::::::::::::::::::::::::SQRT::::::::::::::::::::::::::\\n\")\n",
    "# print data by the numbers!\n",
    "print(f\"number of clusters that were updated with proteins: {len(sqrt_qualifying_proteins.keys())}\\n\")\n",
    "\n",
    "# clusters that are functionally enriched\n",
    "print(f\"number of functionally enriched clusters (modules) out of {clusters.get_num_clusters()} original clusters: {original_fe.enrichment['Module'].nunique()}\")\n",
    "print(f\"number of functionally enriched clusters after addition of all proteins: {sqrt_fe.enrichment['Module'].nunique()}\")\n",
    "print(f\"\")\n",
    "\n",
    "\n",
    "#significant P-values!!!\n",
    "print(f\"number of significant pvals in original clusters before updating: {original_fe.enrichment['Fishers_pvalue'].count()}\")\n",
    "print(f\"number of significant pvals in clusters with all proteins added: {sqrt_fe.enrichment['Fishers_pvalue'].count()}\")\n",
    "\n",
    "\n",
    "print(f\"\")\n",
    "print(f\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of functionally enriched clusters after addition of 3 proteins: 208\n"
     ]
    }
   ],
   "source": [
    "from recipe_utils import top_n_proteins\n",
    "three_sqrt_qualifying_proteins = top_n_proteins(sqrt_qualifying_proteins, n=3)\n",
    "three_sqrt_query_filepath = directory + \"three_prot_clusters.txt\"\n",
    "print_querylist_of_clusters_to_file(clusters, clusters.get_all_cluster_labels(), three_sqrt_query_filepath, three_sqrt_qualifying_proteins)\n",
    "sqrt_three_fe = get_initialized_fe(background_proteins_filepath, term_mapping_filepath, termlist = background_go_terms)\n",
    "sqrt_three_fe.importFiles({'query': three_sqrt_query_filepath })\n",
    "sqrt_three_fe.run(cluster=False)\n",
    "print(f\"number of functionally enriched clusters after addition of 3 proteins: {sqrt_three_fe.enrichment['Module'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_qualifying_clusters, half_qualifying_proteins = find_clusters_and_proteins_together(matrix, clusters, degreelist, cluster_ratio=0, cluster_constant=2, use_sqrt=False, protein_ratio=.50, protein_constant=0)\n",
    "quarter_qualifying_clusters, quarter_qualifying_proteins = find_clusters_and_proteins_together(matrix, clusters, degreelist, cluster_ratio=0, cluster_constant=2, use_sqrt=False, protein_ratio=.25, protein_constant=0)\n",
    "tenth_qualifying_clusters, tenth_qualifying_proteins = find_clusters_and_proteins_together(matrix, clusters, degreelist, cluster_ratio=0, cluster_constant=2, use_sqrt=False, protein_ratio=.10, protein_constant=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of functionally enriched clusters after addition of 1/2 proteins: 208\n",
      "number of functionally enriched clusters after addition of 1/4 proteins: 208\n",
      "number of functionally enriched clusters after addition of 1/10 proteins: 209\n",
      "{}\n",
      "{}\n",
      "{0: ['RGL3'], 1: ['RBL2'], 4: ['AATF', 'TBL3', 'WDR36', 'SUPT5H'], 6: ['LYN'], 7: ['LCK'], 10: ['SDC3'], 14: ['RBL2'], 22: ['DLSTP', 'SLC25A6', 'PIK3C2A', 'NDUFS1', 'RPN2'], 25: ['RPA1'], 33: ['FARSA', 'EIF4G3'], 39: ['LETM1', 'PCBP3', 'RARA', 'UBXN1', 'SNX4', 'S100A7', 'SLC9A3R2', 'VIL2', 'RCN2', 'POLR2J3', 'EIF3F', 'TRMT112', 'TFG', 'PSMB7', 'CFTR', 'ELL2', 'TMED2', 'AIFM1', 'RHOA', 'CUL2', 'TCEB1', 'DDX21', 'ANAPC1', 'TPM3P4', 'MORF4L1', 'PSMB2', 'PSMD6', 'DEPDC5', 'COPB1', 'DNM2', 'PSMD14', 'VARS', 'PSMD7', 'LCK', 'CCNC', 'TPM3', 'DNAJA1', 'AHSA1', 'SQRDL', 'PSMA6', 'CUL1', 'SMARCD1', 'PSME4', 'PCMT1', 'PSMD8', 'POLR2J', 'PSMA5', 'HSPA6', 'MCM7', 'MSH6', 'PSMD13', 'PSMB4', 'TAF5', 'POLR1E', 'PSMB3', 'PSMB1', 'UBR5', 'KPNA5', 'PSMA2', 'TAF6', 'SMC4', 'PSMB5', 'EIF3A', 'MAP3K3', 'PSMA1', 'SMARCA2', 'DDB1', 'KPNA6', 'PSMA3', 'POLR2H', 'KPNA2', 'CCT3', 'COPB2', 'POLR2L', 'PSMC6', 'PRDX2', 'PPP2R1A', 'P4HB', 'SMARCC2', 'MYBBP1A', 'CCT4', 'HIST1H2AH', 'HIST1H2AC', 'SMARCA4'], 40: ['SEC23A', 'SETX', 'PAK4', 'MLLT4', 'SMARCB1', 'LYN', 'EIF5AP1', 'CCNH', 'MNAT1', 'EPRS', 'COPB2', 'RPS7P1', 'PPP1R12A', 'CTPS', 'PTK2B', 'EIF4G3', 'EIF4E'], 41: ['VCP', 'HSP90AA2', 'SMARCA4'], 42: ['ATXN10', 'IMMT', 'KIAA1967', 'CBL', 'SNRPA1', 'PIK3R1', 'PRPF8', 'CBLB', 'RPN2', 'COPB2', 'SLC25A5'], 43: ['SUPT4H1', 'USP10', 'TIA1', 'BTF3L4', 'BUB1B', 'YEATS4', 'RAD23B', 'MORF4L1', 'PSMB2', 'CBL', 'CTR9', 'CDK8', 'CHEK2', 'PRPF3', 'PSMD11', 'RAB6C', 'PSMB4', 'RAB6B', 'RBL2', 'CTNNB1', 'PSMB5', 'LARP2', 'EIF4E'], 44: ['CBL', 'CSNK1G3', 'RANBP2'], 48: ['UBE2B', 'UBE2A', 'GRAP', 'PSMB2', 'DEPDC5', 'SUPT3H', 'SUMO1P3', 'TAF12', 'RAB6B', 'PHB2', 'TAF5', 'CTNNB1', 'EIF3A', 'NEDD4L', 'PSMA3', 'PDPK1', 'PTPN11', 'HDAC1'], 49: ['SUMO1P3'], 50: ['SMAD2', 'SMAD3'], 57: ['RAD54L', 'NEDD4', 'RP11-297B17.2', 'UTP14A', 'RPS29', 'UTP15', 'SUPT16H', 'SUMO1P3', 'NOC2L', 'PRPF3', 'RBM28', 'EIF5B', 'PCAF', 'KRI1', 'RBM34', 'TSR1', 'EIF3CL', 'RRP12', 'ARHGAP15', 'NOL6', 'EIF3C', 'IMPDH1', 'DDX18', 'SMARCC2', 'NAT10'], 61: ['DLG3', 'RPL38', 'RPS26'], 65: ['LIMK1', 'G3BP1', 'RPL28', 'VCP', 'TUBA1B', 'PTPN11', 'YES1'], 66: ['FGFR1'], 67: ['NME2', 'ACTR3', 'PPP1CB', 'SPDYA'], 72: ['CHEK2', 'TGFBR1', 'NEDD4L', 'TOP2A', 'OLA1', 'P4HB', 'MMS19'], 75: ['CLPB', 'DDOST', 'RBL2', 'SMARCA4'], 78: ['PTK2'], 80: ['RBL2'], 81: ['IGHV4-31', 'FGFR1', 'NEDD4L', 'PDPK1'], 84: ['PTPN12', 'AHCY', 'ABL1', 'ARPC3', 'PPP2R1A', 'PTPN11'], 86: ['UBE2G2', 'TP53'], 89: ['CHUK'], 92: ['RTN4'], 93: ['CD4', 'PGM1', 'SKIV2L2', 'LMNB1', 'SMAD4', 'DHX30', 'PMM2', 'SART1', 'AHSA1', 'CDK4', 'PPA1', 'PSMD11', 'EIF2S3', 'LYN', 'NME2', 'ACO2', 'RANP1', 'EIF6', 'CAMK2A', 'PSMD3', 'CAPZB'], 94: ['RAB6C', 'RAB6B', 'KIAA0368', 'TOP2A', 'OLA1'], 97: ['GNG12', 'QTRTD1', 'FGA', 'TTR', 'KRT9', 'APOC1', 'APOA1', 'COPB1', 'PLCG1', 'ALB', 'KRT14', 'FN1', 'KRT1', 'KRT10', 'HSPA6', 'ABL1', 'EEF1A2', 'PPP6C', 'HDAC1', 'HNRNPC'], 104: ['RAD9A', 'NRIP1', 'SETDB2', 'GNAO1', 'HOMER2', 'NCOA2', 'CREB1', 'NCOA1', 'NUP214', 'NCOA3', 'C1QA', 'APOA1', 'ALB', 'KRT14', 'CREBBP', 'RELA', 'TP53', 'PTPN14', 'CTNNB1', 'RANP1', 'KPNA2'], 105: ['PLCG1', 'TGFBR1'], 107: ['RANBP5'], 111: ['SEC22A', 'ATP13A1', 'SHFM1', 'HCLS1', 'SFN', 'NUP107', 'CBL', 'LSM1', 'RPL9P7', 'RPL9', 'PSMC5', 'PSMB3', 'PSMB1', 'RPL38', 'NEDD4L', 'POLR2C', 'RPS7P1', 'PPP6C', 'IPO9', 'PTK2B'], 117: ['SKIV2L', 'RGL3', 'SUPT5H', 'RPL37A', 'TSR1', 'NEDD4L', 'EIF3B', 'NAT10'], 118: ['MAP2K2'], 122: ['SYNE1', 'RPL29', 'SUMO1P3', 'RPS26P8', 'RPS26P10', 'PPP6C', 'HNRNPC', 'RPS26', 'SMARCA4'], 123: ['SF3A2'], 130: ['RBL2'], 133: ['HTATIP', 'RBL2'], 140: ['GIT1', 'CENPC1', 'SEPT3', 'RBBP6', 'SMC3', 'PYGL', 'ERO1LB', 'ITPR1', 'CLP1', 'IKBKG', 'NUDC', 'EIF3G', 'PI4KA', 'SYNE1', 'TBL3', 'SEC13', 'DHX30', 'CLASP2', 'SEH1L', 'EIF5B', 'SLC25A6', 'TGFBR1', 'KIAA0368', 'EIF3CL', 'IRS4', 'HIST1H2BD', 'H2BFS', 'HIST2H2BA', 'HIST1H2BJ', 'HIST3H2BB', 'HIST1H2BB', 'EIF3A', 'PSMD1', 'LARP2', 'HIST1H2BM', 'NOL6', 'CCT5', 'EIF3C', 'RSL1D1', 'HIST2H2BF', 'CCT2', 'RPS7P1', 'COPG', 'PSMD3', 'DDX18', 'EIF4G3', 'SMARCC2', 'KIAA0664', 'NAT10', 'HIST1H2AH', 'HIST1H2AC'], 143: ['UTP20', 'COPB2'], 144: ['CAMK1D', 'RPL29', 'MAX', 'PHB2', 'COPA', 'SLC25A5', 'SLC25A3', 'PTK2B', 'YES1'], 147: ['SETDB1', 'SORCS2', 'SORT1', 'PPA1', 'PSMD8', 'EIF5AP1', 'EIF6', 'EIF4E'], 153: ['HDAC1'], 161: ['VDAC2', 'ATP6V0D1', 'RANP1'], 165: ['KIF5B', 'CANX', 'MME', 'EIF3J', 'VHL', 'PPP1CB', 'SPDYA'], 169: ['KIAA1377'], 171: ['PSMB1'], 172: ['EP300', 'RNPS1', 'HSP90AA2'], 176: ['TALDO1', 'PPP2CB', 'PRPF40A', 'PPP2CA', 'KPNA5', 'PRPF8', 'KPNA6'], 177: ['IKBKE', 'SMARCC2', 'SMARCA4'], 178: ['IMPDH1', 'OLA1'], 183: ['CTNNB1', 'MOBKL1B', 'RPA1'], 184: ['SLC25A6', 'DDX18'], 185: ['CRK', 'ALB', 'NSF'], 195: ['HIST1H2AC'], 199: ['NCK1'], 203: ['SOD1', 'PLCG1', 'NCK1', 'TAF12', 'PIK3R1', 'KRT18', 'PLS3', 'CHUK', 'EIF6', 'PFKP', 'EIF4E'], 205: ['UBQLN1', 'TCEB1', 'TCEB2', 'VHL', 'PRKAA2', 'NEDD4L', 'SMARCC2'], 209: ['VPS35', 'ARHGAP15', 'RANP1', 'EIF6', 'DDX18', 'IPO9'], 210: ['PDPK1']}\n"
     ]
    }
   ],
   "source": [
    "half_query_filepath = directory + \"half_clusters.txt\"\n",
    "print_querylist_of_clusters_to_file(clusters, clusters.get_all_cluster_labels(), half_query_filepath, half_qualifying_proteins)\n",
    "half_fe = get_initialized_fe(background_proteins_filepath, term_mapping_filepath, termlist = background_go_terms)\n",
    "half_fe.importFiles({'query': half_query_filepath })\n",
    "half_fe.run(cluster=False)\n",
    "\n",
    "print(f\"number of functionally enriched clusters after addition of 1/2 proteins: {half_fe.enrichment['Module'].nunique()}\")\n",
    "\n",
    "\n",
    "quarter_query_filepath = directory + \"quarter_clusters.txt\"\n",
    "print_querylist_of_clusters_to_file(clusters, clusters.get_all_cluster_labels(), quarter_query_filepath, quarter_qualifying_proteins)\n",
    "quarter_fe = get_initialized_fe(background_proteins_filepath, term_mapping_filepath, termlist = background_go_terms)\n",
    "quarter_fe.importFiles({'query': quarter_query_filepath })\n",
    "quarter_fe.run(cluster=False)\n",
    "\n",
    "print(f\"number of functionally enriched clusters after addition of 1/4 proteins: {quarter_fe.enrichment['Module'].nunique()}\")\n",
    "\n",
    "\n",
    "tenth_query_filepath = directory + \"tenth_clusters.txt\"\n",
    "print_querylist_of_clusters_to_file(clusters, clusters.get_all_cluster_labels(), tenth_query_filepath, tenth_qualifying_proteins)\n",
    "tenth_fe = get_initialized_fe(background_proteins_filepath, term_mapping_filepath, termlist = background_go_terms)\n",
    "tenth_fe.importFiles({'query': tenth_query_filepath })\n",
    "tenth_fe.run(cluster=False)\n",
    "\n",
    "print(f\"number of functionally enriched clusters after addition of 1/10 proteins: {tenth_fe.enrichment['Module'].nunique()}\")\n",
    "\n",
    "\n",
    "print(half_qualifying_proteins)\n",
    "print(quarter_qualifying_proteins)  \n",
    "print(tenth_qualifying_proteins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of functionally enriched clusters after addition of 3 1/10 proteins: 209\n"
     ]
    }
   ],
   "source": [
    "from recipe_utils import top_n_proteins\n",
    "\n",
    "three_tenth_qualifying_proteins = top_n_proteins(tenth_qualifying_proteins, n=3)\n",
    "three_tenth_query_filepath = directory + \"three_tenth_clusters.txt\"\n",
    "print_querylist_of_clusters_to_file(clusters, clusters.get_all_cluster_labels(), three_tenth_query_filepath, three_tenth_qualifying_proteins)\n",
    "half_tenth_fe = get_initialized_fe(background_proteins_filepath, term_mapping_filepath, termlist = background_go_terms) \n",
    "half_tenth_fe.importFiles({'query': three_tenth_query_filepath })\n",
    "half_tenth_fe.run(cluster=False)\n",
    "print(f\"number of functionally enriched clusters after addition of 3 1/10 proteins: {half_tenth_fe.enrichment['Module'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62f9e904ff1d4fa6e27f2984f15409dfffcff7468a54928ca0992224464fe58b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
